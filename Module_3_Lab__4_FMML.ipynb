{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsL6K9Ge+2i/HyT2ryAagW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohanpeerla/Module-3-lab-4/blob/master/Module_3_Lab__4_FMML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.Instead of using cross-validation, we could also split our dataset into three sets- train, validation, and test set. The training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
        "What do you think are the pros/cons of this method ?\n",
        "\n",
        "\n",
        "Pros:\n",
        "\n",
        "Simplicity: It's straightforward and easy to implement.\n",
        "Computational Efficiency: Training on a single split is computationally cheaper than multiple iterations in cross-validation.\n",
        "Interpretability: Results on the test set give a clear, final performance metric for your model.\n",
        "# New section\n",
        "Cons:\n",
        "\n",
        "Sensitivity to Split: The performance may heavily depend on how you've divided the data. A different split might lead to different results.\n",
        "Limited Data: With a fixed split, you might not use all your data for training, which could be a drawback, especially with smaller datasets.\n",
        "Overfitting to Validation Set: If you iteratively tweak your model based on validation performance, there's a risk of overfitting to the validation set.\n",
        "It really depends on your dataset size, the problem at hand, and your computational resources. Each approach has its time and place!"
      ],
      "metadata": {
        "id": "VkPu-PW_1Y7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.Is K-Fold cross validation an exhaustive or non-exhaustive cross validation method ? Justify your answer.\n",
        "\n",
        "\n",
        "K-Fold cross-validation is an exhaustive cross-validation method. In K-Fold cross-validation, the dataset is divided into K subsets (folds), and the model is trained and evaluated K times, each time using a different fold as the test set and the remaining folds as the training set.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "1. **Exhaustive Evaluation:** K-Fold CV ensures that every data point is used for both training and testing at least once. This provides a more comprehensive evaluation of the model's performance across the entire dataset.\n",
        "\n",
        "2. **Reduced Variance:** By averaging the performance metrics over K folds, the variability in the evaluation results is reduced compared to a single train-validation split. This gives a more reliable estimate of the model's performance."
      ],
      "metadata": {
        "id": "Vzjmv45616IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TASK-1:\n",
        "## In the above case, we saw K-Fold cross validation, where we split the dataset into K consecutive folds without taking anything else into account.\n",
        "## Stratified KFold is another strategy that is commonly used, which preserves the percentage of samples for each class in the folds.\n",
        "## Implement Stratified KFold (refer Sklearn docs) and display the results you obtain\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification  # Replace this with your actual data import\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_results = cross_val_score(model, X, y, cv=stratified_kfold, scoring='accuracy')\n",
        "\n",
        "print(\"Stratified K-Fold Cross-Validation Results:\")\n",
        "print(\"Accuracy for each fold:\", cv_results)\n",
        "print(\"Average Accuracy:\", cv_results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ydKVaLs2KQj",
        "outputId": "4e54c476-2500-4f3c-b340-55fcffed69cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stratified K-Fold Cross-Validation Results:\n",
            "Accuracy for each fold: [0.905 0.88  0.82  0.845 0.845]\n",
            "Average Accuracy: 0.859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TASK-2:\n",
        "## Plot a confusion matrix for the classification above on the scaled data (using the optimal value of k)\n",
        "## Also print out the Precision, Recall and F1-score values\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate dummy data or use your actual data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Assuming you have already found the optimal value of k and scaled your data\n",
        "optimal_k = 5  # Replace this with your optimal k value\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=optimal_k)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "HYRc25Iq2pe9",
        "outputId": "f18db6e0-80bb-4004-d9d7-9e2f073b140b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       111\n",
            "           1       0.86      0.84      0.85        89\n",
            "\n",
            "    accuracy                           0.87       200\n",
            "   macro avg       0.87      0.87      0.87       200\n",
            "weighted avg       0.87      0.87      0.87       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TASK-3:\n",
        "## Perform K-Fold Cross validation after standardizing the data. Display your results.\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_standardized = scaler.fit_transform(X)\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_results = cross_val_score(model, X_standardized, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "print(\"K-Fold Cross-Validation Results after Standardization:\")\n",
        "print(\"Accuracy for each fold:\", cv_results)\n",
        "print(\"Average Accuracy:\", cv_results.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLA6mT8N224H",
        "outputId": "2fc51fce-4447-489a-f48b-7b06197ca5da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Fold Cross-Validation Results after Standardization:\n",
            "Accuracy for each fold: [0.87  0.855 0.82  0.88  0.855]\n",
            "Average Accuracy: 0.8559999999999999\n"
          ]
        }
      ]
    }
  ]
}